{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "from bs4 import BeautifulSoup\n",
    "import contractions\n",
    "import unidecode\n",
    "import re\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "import torch\n",
    "import string\n",
    "from sklearn.utils import shuffle\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM,AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import BertTokenizer, BertForSequenceClassification,RobertaForSequenceClassification,RobertaTokenizer\n",
    "from transformers import EarlyStoppingCallback\n",
    "# from gensim.parsing.preprocessing import remove_stopwords\n",
    "from transformers import XLMRobertaModel, XLMRobertaTokenizer\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def removeHtml(sentence):\n",
    "    soup = BeautifulSoup(sentence, \"html.parser\")\n",
    "    stripped_text = soup.get_text(separator=\" \")\n",
    "    return stripped_text\n",
    "\n",
    "def removePuncu(sentence):\n",
    "    res = re.sub(r'[^\\w\\s]', '', sentence)\n",
    "    return res\n",
    "\n",
    "def removeLink(sentence):\n",
    "    result = re.sub(r'http\\S+', '', sentence)\n",
    "    return result\n",
    "\n",
    "def removeWhiteSpaces(sentence):\n",
    "    sentence = sentence.strip()\n",
    "    return \" \".join(sentence.split())\n",
    "\n",
    "def expand_contractions(sentence):\n",
    "    sentence = contractions.fix(sentence)\n",
    "    return sentence\n",
    "\n",
    "def removeAccented(sentence):\n",
    "    sentence = unidecode.unidecode(sentence)\n",
    "    return sentence\n",
    "\n",
    "def removeSpec(sentence):\n",
    "    sentence = re.sub(\"[^A-Z]\", \" \", sentence, 0, re.IGNORECASE)\n",
    "    return sentence\n",
    "\n",
    "def removeNum(sentence):\n",
    "    pattern = r'[0-9]'\n",
    "    sentence = re.sub(pattern, '', sentence)\n",
    "    return sentence\n",
    "\n",
    "def lowerCase(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    return sentence\n",
    "    \n",
    "# def removeUser(sentence):\n",
    "#     remove = re.compile('(\\s*)user(\\s*)')\n",
    "#     sentence = remove.sub(\" \", sentence)\n",
    "#     return sentence\n",
    "\n",
    "# with open(r'C:\\Users\\LEGION\\Documents\\Untitled Folder 2\\Emoji_Dict.p', 'rb') as fp:\n",
    "#     Emoji_Dict = pickle.load(fp)\n",
    "# Emoji_Dict = {v: k for k, v in Emoji_Dict.items()}\n",
    "\n",
    "# def convertEmoji(sentence):\n",
    "#     for emot in Emoji_Dict:\n",
    "#         sentence = re.sub(r'('+emot+')', \"\".join(Emoji_Dict[emot].replace(\",\",\"\").replace(\":\",\"\").split()),sentence)\n",
    "#     return sentence\n",
    "\n",
    "def add_labels(value):\n",
    "    if value == 'positive':\n",
    "        return 2\n",
    "    elif value == 'negative':\n",
    "        return 0\n",
    "    elif value == 'neutral':\n",
    "        return 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data):\n",
    "    sent_or_word = 'translation_sentence_level'\n",
    "    data[sent_or_word] = data[sent_or_word].apply(lambda x: lowerCase(x))\n",
    "    data[sent_or_word] = data[sent_or_word].apply(lambda x: removePuncu(x))\n",
    "    data[sent_or_word] = data[sent_or_word].apply(lambda x: removeSpec(x))\n",
    "    data[sent_or_word] = data[sent_or_word].apply(lambda x: removeHtml(x))\n",
    "\n",
    "    data[sent_or_word] = data[sent_or_word].apply(lambda x: removeAccented(x))\n",
    "    data[sent_or_word] = data[sent_or_word].apply(lambda x: removeLink(x))\n",
    "    data[sent_or_word] = data[sent_or_word].apply(lambda x: removeNum(x))\n",
    "\n",
    "    data[sent_or_word] = data[sent_or_word].apply(lambda x: expand_contractions(x))\n",
    "#     da[sent_or_word] = da[sent_or_word].apply(lambda x: convertEmoji(x))\n",
    "    data[sent_or_word] = data[sent_or_word].apply(lambda x: removeWhiteSpaces(x))\n",
    "    # data[sent_or_word] = data[sent_or_word].apply(lambda x: removeUser(x))\n",
    "    x = data[sent_or_word].to_list()\n",
    "    y = list(data['categorical_labels']) \n",
    "    \n",
    "    return x,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        if self.labels:\n",
    "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results_dict = {\"Model_Name\":[], \"Accuracy\": [], 'Recall': [], 'Precision': [], \"f1\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /home/ablstation2/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/roberta-base/resolve/main/vocab.json from cache at /home/ablstation2/.cache/huggingface/transformers/d3ccdbfeb9aaa747ef20432d4976c32ee3fa69663b379deb253ccfce2bb1fdc5.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "loading file https://huggingface.co/roberta-base/resolve/main/merges.txt from cache at /home/ablstation2/.cache/huggingface/transformers/cafdecc90fcab17011e12ac813dd574b4b3fea39da6dd817813efa010262ff3f.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/roberta-base/resolve/main/tokenizer.json from cache at /home/ablstation2/.cache/huggingface/transformers/d53fc0fa09b8342651efd4073d75e19617b3e51287c2a535becda5808a8db287.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n",
      "loading file https://huggingface.co/roberta-base/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/roberta-base/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/roberta-base/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /home/ablstation2/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file modelMergedRemoveEmojiRoberta/roberta-base_Train_merged_Roberta_Removed_Emoji/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"modelMergedRemoveEmojiRoberta/roberta-base_Train_merged_Roberta_Removed_Emoji\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file modelMergedRemoveEmojiRoberta/roberta-base_Train_merged_Roberta_Removed_Emoji/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at modelMergedRemoveEmojiRoberta/roberta-base_Train_merged_Roberta_Removed_Emoji.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "path = \"modelMergedRemoveEmojiRoberta/roberta-base_Train_merged_Roberta_Removed_Emoji\"\n",
    "max_length = 128\n",
    "num_labels = 3\n",
    "# task = 'sentiment'\n",
    "modelName = \"roberta-base\"\n",
    "# modelName = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
    "# safe_model_name = sanitize(model_name)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelName)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "newModelNameForSaving = modelName.split(\"/\")[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "100%|██████████| 1/1 [10:28<00:00, 628.30s/it]\n",
      "***** Running Prediction *****\n",
      "  Num examples = 826\n",
      "  Batch size = 256\n",
      "/home/ablstation2/.pyenv/versions/3.6.5/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|██████████| 2/2 [00:00<00:00, 11.81it/s]PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "100%|██████████| 2/2 [00:00<00:00, 10.41it/s]\n",
      "***** Running Prediction *****\n",
      "  Num examples = 388\n",
      "  Batch size = 256\n",
      "/home/ablstation2/.pyenv/versions/3.6.5/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta-base\n",
      "accuracy: 0.6101694915254238\n",
      "recall: 0.6101694915254238\n",
      "precision: 0.6566553530268914\n",
      "f1: 0.6045043905764667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "100%|██████████| 1/1 [00:00<00:00, 32.32it/s]\n",
      "***** Running Prediction *****\n",
      "  Num examples = 453\n",
      "  Batch size = 256\n",
      "/home/ablstation2/.pyenv/versions/3.6.5/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta-base\n",
      "accuracy: 0.41494845360824745\n",
      "recall: 0.41494845360824745\n",
      "precision: 0.545644292954916\n",
      "f1: 0.4415317804974339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "100%|██████████| 1/1 [00:00<00:00, 33.41it/s]\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1840\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta-base\n",
      "accuracy: 0.609271523178808\n",
      "recall: 0.609271523178808\n",
      "precision: 0.6026853683606076\n",
      "f1: 0.6051900482658324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ablstation2/.pyenv/versions/3.6.5/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.55it/s]PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.48it/s]\n",
      "***** Running Prediction *****\n",
      "  Num examples = 414\n",
      "  Batch size = 256\n",
      "/home/ablstation2/.pyenv/versions/3.6.5/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta-base\n",
      "accuracy: 0.6701086956521739\n",
      "recall: 0.6701086956521739\n",
      "precision: 0.6730281812904148\n",
      "f1: 0.6610810839417579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "100%|██████████| 1/1 [00:00<00:00, 46.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta-base\n",
      "accuracy: 0.5217391304347826\n",
      "recall: 0.5217391304347826\n",
      "precision: 0.6326635802061132\n",
      "f1: 0.538762812947912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 2677\n",
      "  Batch size = 256\n",
      "/home/ablstation2/.pyenv/versions/3.6.5/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      " 83%|████████▎ | 5/6 [00:01<00:00,  4.06it/s]PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "100%|██████████| 6/6 [00:01<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta-base\n",
      "accuracy: 0.730668658946582\n",
      "recall: 0.730668658946582\n",
      "precision: 0.7453427526895238\n",
      "f1: 0.7314010735441907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 2090\n",
      "  Batch size = 256\n",
      "/home/ablstation2/.pyenv/versions/3.6.5/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      " 80%|████████  | 4/5 [00:00<00:00,  4.17it/s]PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.86it/s]\n",
      "***** Running Prediction *****\n",
      "  Num examples = 493\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta-base\n",
      "accuracy: 0.7052631578947368\n",
      "recall: 0.7052631578947368\n",
      "precision: 0.7273498812952318\n",
      "f1: 0.7044651398103275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ablstation2/.pyenv/versions/3.6.5/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "100%|██████████| 1/1 [00:00<00:00, 34.57it/s]\n",
      "***** Running Prediction *****\n",
      "  Num examples = 766\n",
      "  Batch size = 256\n",
      "/home/ablstation2/.pyenv/versions/3.6.5/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta-base\n",
      "accuracy: 0.6389452332657201\n",
      "recall: 0.6389452332657201\n",
      "precision: 0.687160418858556\n",
      "f1: 0.6281719597415099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 19.32it/s]PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "100%|██████████| 2/2 [00:00<00:00, 14.21it/s]\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1497\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta-base\n",
      "accuracy: 0.618798955613577\n",
      "recall: 0.618798955613577\n",
      "precision: 0.6387907074004479\n",
      "f1: 0.6194296783650607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ablstation2/.pyenv/versions/3.6.5/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      " 67%|██████▋   | 2/3 [00:00<00:00, 12.67it/s]PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "100%|██████████| 3/3 [00:00<00:00,  9.11it/s]\n",
      "***** Running Prediction *****\n",
      "  Num examples = 203\n",
      "  Batch size = 256\n",
      "/home/ablstation2/.pyenv/versions/3.6.5/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta-base\n",
      "accuracy: 0.6158984635938544\n",
      "recall: 0.6158984635938544\n",
      "precision: 0.617179374247978\n",
      "f1: 0.6160045326944797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta-base\n",
      "accuracy: 0.4039408866995074\n",
      "recall: 0.4039408866995074\n",
      "precision: 0.5575742821942243\n",
      "f1: 0.4320450499016881\n"
     ]
    }
   ],
   "source": [
    "allTest = os.listdir('emojiRemovedFiles/test')\n",
    "\n",
    "for file in allTest:\n",
    "    newModelNameForSaving = modelName.split(\"/\")[-1]\n",
    "    def compute_metrics(p):\n",
    "        pred, labels = p\n",
    "        pred = np.argmax(pred, axis=1)\n",
    "        accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "        recall = recall_score(y_true=labels, y_pred=pred,average='weighted')\n",
    "        precision = precision_score(y_true=labels, y_pred=pred,average='weighted')\n",
    "        f1 = f1_score(y_true=labels, y_pred=pred,average='weighted')\n",
    "\n",
    "        return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        output_dir=\"checkpointsTestFileToFile/{}_{}\".format(newModelNameForSaving,file.split(\".\")[0]),\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        per_device_train_batch_size=256,\n",
    "        per_device_eval_batch_size=256,\n",
    "        num_train_epochs=5,\n",
    "        seed=7,\n",
    "        load_best_model_at_end=True,\n",
    "        save_strategy='epoch',\n",
    "        overwrite_output_dir=True)\n",
    "        #save_strategy = \"no\"\n",
    "\n",
    "    trainer = Trainer(\n",
    "      model=model,\n",
    "      args=args,\n",
    "      compute_metrics = compute_metrics,\n",
    "      callbacks=[EarlyStoppingCallback(early_stopping_patience=3)])\n",
    "\n",
    "\n",
    "    test_data = pd.read_csv(\"emojiRemovedFiles/test/{}\".format(file),sep='\\t')\n",
    "    test_data = test_data[test_data['translation_sentence_level'].notna()]\n",
    "    test_data['categorical_labels'] = test_data['label'].map(add_labels)\n",
    "\n",
    "    X_test, y_test = preprocessing(test_data)\n",
    "\n",
    "\n",
    "    X_test_tokenized = tokenizer(X_test, padding=True, truncation=True, max_length=max_length,add_special_tokens=True)\n",
    "\n",
    "\n",
    "    test_dataset = Dataset(X_test_tokenized, y_test)\n",
    "\n",
    "\n",
    "    predictions = trainer.predict(test_dataset)\n",
    "\n",
    "    pred = np.argmax(predictions.predictions, axis=-1)\n",
    "\n",
    "  \n",
    "    accuracy = accuracy_score(y_true=y_test, y_pred=pred)\n",
    "    recall = recall_score(y_true=y_test, y_pred=pred,average='weighted')\n",
    "    precision = precision_score(y_true=y_test, y_pred=pred,average='weighted')\n",
    "    f1 = f1_score(y_true=y_test, y_pred=pred,average='weighted')\n",
    "\n",
    "    print(modelName)\n",
    "    print(\"accuracy: {}\".format(accuracy))\n",
    "    print(\"recall: {}\".format(recall))\n",
    "    print(\"precision: {}\".format(precision))\n",
    "    print(\"f1: {}\".format(f1))\n",
    "\n",
    "    model_results_dict['Model_Name'].append(file)\n",
    "    model_results_dict['Accuracy'].append(accuracy)\n",
    "    model_results_dict['Recall'].append(recall)\n",
    "    model_results_dict['Precision'].append(precision)\n",
    "    model_results_dict['f1'].append(f1)\n",
    "\n",
    "    df = pd.DataFrame(data = model_results_dict)\n",
    "    df.to_csv(\"{}_FileToFileRemovedEmojiRobertaresults.csv\".format(newModelNameForSaving))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.5 64-bit ('3.6.5')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9c5472c625688a4fda46769efa78306e9889cc6db92cebd22ca1efa0057f033e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
