{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "from bs4 import BeautifulSoup\n",
    "import contractions\n",
    "import unidecode\n",
    "import re\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "import torch\n",
    "import string\n",
    "from sklearn.utils import shuffle\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM,AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import BertTokenizer, BertForSequenceClassification,RobertaForSequenceClassification,RobertaTokenizer\n",
    "from transformers import EarlyStoppingCallback\n",
    "# from gensim.parsing.preprocessing import remove_stopwords\n",
    "from transformers import XLMRobertaModel, XLMRobertaTokenizer\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def removeHtml(sentence):\n",
    "    soup = BeautifulSoup(sentence, \"html.parser\")\n",
    "    stripped_text = soup.get_text(separator=\" \")\n",
    "    return stripped_text\n",
    "\n",
    "def removePuncu(sentence):\n",
    "    res = re.sub(r'[^\\w\\s]', '', sentence)\n",
    "    return res\n",
    "\n",
    "def removeLink(sentence):\n",
    "    result = re.sub(r'http\\S+', '', sentence)\n",
    "    return result\n",
    "\n",
    "def removeWhiteSpaces(sentence):\n",
    "    sentence = sentence.strip()\n",
    "    return \" \".join(sentence.split())\n",
    "\n",
    "def expand_contractions(sentence):\n",
    "    sentence = contractions.fix(sentence)\n",
    "    return sentence\n",
    "\n",
    "def removeAccented(sentence):\n",
    "    sentence = unidecode.unidecode(sentence)\n",
    "    return sentence\n",
    "\n",
    "def removeSpec(sentence):\n",
    "    sentence = re.sub(\"[^A-Z]\", \" \", sentence, 0, re.IGNORECASE)\n",
    "    return sentence\n",
    "\n",
    "def removeNum(sentence):\n",
    "    pattern = r'[0-9]'\n",
    "    sentence = re.sub(pattern, '', sentence)\n",
    "    return sentence\n",
    "\n",
    "def lowerCase(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    return sentenceMergedData/testDataMerged.tsv(\\s*)user(\\s*)')\n",
    "#     sentence = remove.sub(\" \", sentence)\n",
    "#     return sentence\n",
    "\n",
    "# with open(r'C:\\Users\\LEGION\\Documents\\Untitled Folder 2\\Emoji_Dict.p', 'rb') as fp:\n",
    "#     Emoji_Dict = pickle.load(fp)\n",
    "# Emoji_Dict = {v: k for k, v in Emoji_Dict.items()}\n",
    "\n",
    "# def convertEmoji(sentence):\n",
    "#     for emot in Emoji_Dict:\n",
    "#         sentence = re.sub(r'('+emot+')', \"\".join(Emoji_Dict[emot].replace(\",\",\"\").replace(\":\",\"\").split()),sentence)\n",
    "#     return sentence\n",
    "\n",
    "def add_labels(value):\n",
    "    if value == 'positive':\n",
    "        return 2\n",
    "    elif value == 'negative':\n",
    "        return 0\n",
    "    elif value == 'neutral':\n",
    "        return 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data):\n",
    "    sent_or_word = 'translation_sentence_level'\n",
    "    data[sent_or_word] = data[sent_or_word].apply(lambda x: lowerCase(x))\n",
    "    data[sent_or_word] = data[sent_or_word].apply(lambda x: removePuncu(x))\n",
    "    data[sent_or_word] = data[sent_or_word].apply(lambda x: removeSpec(x))\n",
    "    data[sent_or_word] = data[sent_or_word].apply(lambda x: removeHtml(x))\n",
    "\n",
    "    data[sent_or_word] = data[sent_or_word].apply(lambda x: removeAccented(x))\n",
    "    data[sent_or_word] = data[sent_or_word].apply(lambda x: removeLink(x))\n",
    "    data[sent_or_word] = data[sent_or_word].apply(lambda x: removeNum(x))\n",
    "\n",
    "    data[sent_or_word] = data[sent_or_word].apply(lambda x: expand_contractions(x))\n",
    "#     da[sent_or_word] = da[sent_or_word].apply(lambda x: convertEmoji(x))\n",
    "    data[sent_or_word] = data[sent_or_word].apply(lambda x: removeWhiteSpaces(x))\n",
    "    # data[sent_or_word] = data[sent_or_word].apply(lambda x: removeUser(x))\n",
    "    x = data[sent_or_word].to_list()\n",
    "    y = list(data['categorical_labels']) \n",
    "    \n",
    "    return x,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        if self.labels:\n",
    "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results_dict = {\"Model_Name\":[], \"Accuracy\": [], 'Recall': [], 'Precision': [], \"f1\":[]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /home/ablstation2/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/roberta-base/resolve/main/vocab.json from cache at /home/ablstation2/.cache/huggingface/transformers/d3ccdbfeb9aaa747ef20432d4976c32ee3fa69663b379deb253ccfce2bb1fdc5.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "loading file https://huggingface.co/roberta-base/resolve/main/merges.txt from cache at /home/ablstation2/.cache/huggingface/transformers/cafdecc90fcab17011e12ac813dd574b4b3fea39da6dd817813efa010262ff3f.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/roberta-base/resolve/main/tokenizer.json from cache at /home/ablstation2/.cache/huggingface/transformers/d53fc0fa09b8342651efd4073d75e19617b3e51287c2a535becda5808a8db287.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n",
      "loading file https://huggingface.co/roberta-base/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/roberta-base/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/roberta-base/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /home/ablstation2/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /home/ablstation2/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /home/ablstation2/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "max_length = 128\n",
    "num_labels = 3\n",
    "# task = 'sentiment'\n",
    "model_name = \"roberta-base\"\n",
    "# model_name = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
    "# safe_model_name = sanitize(model_name)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_name, num_labels = num_labels, ignore_mismatched_sizes = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('emojiRemovedFiles/MergedEmojiRemoved/trainDataMerged.tsv', sep = '\\t')\n",
    "val_data = pd.read_csv('emojiRemovedFiles/MergedEmojiRemoved/valDataMerged.tsv', sep = '\\t')\n",
    "train_data = train_data[train_data['translation_sentence_level'].notna()]\n",
    "val_data = val_data[val_data['translation_sentence_level'].notna()]\n",
    "\n",
    "train_data['categorical_labels'] = train_data['label'].map(add_labels)\n",
    "val_data['categorical_labels'] = val_data['label'].map(add_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train = preprocessing(train_data)\n",
    "\n",
    "#splitting the trainData into train test, for checking the performance of our model. \n",
    "x_train_final, x_test_final, y_train_final, y_test_final = train_test_split(x_train, y_train, test_size=0.25, random_state=42, shuffle = True)\n",
    "\n",
    "x_val, y_val = preprocessing(val_data)\n",
    "\n",
    "x_train_tokenized = tokenizer(x_train_final, padding=True, truncation=True, max_length=max_length,add_special_tokens=True)\n",
    "x_val_tokenized = tokenizer(x_val, padding=True, truncation=True, max_length=max_length,add_special_tokens=True)\n",
    "\n",
    "train_dataset = Dataset(x_train_tokenized, y_train_final)\n",
    "val_dataset = Dataset(x_val_tokenized, y_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "        pred, labels = p\n",
    "        pred = np.argmax(pred, axis=1)\n",
    "        accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "        recall = recall_score(y_true=labels, y_pred=pred,average='weighted')\n",
    "        precision = precision_score(y_true=labels, y_pred=pred,average='weighted')\n",
    "        f1 = f1_score(y_true=labels, y_pred=pred,average='weighted')\n",
    "\n",
    "        return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "newModelNameForSaving = model_name.split(\"/\")[-1]\n",
    "x = \"Train_merged_Roberta_Removed_Emoji.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "100%|██████████| 26/26 [10:28<00:00, 24.17s/it]\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"checkpointsMergedRobertaRemoveEmoji/{}_{}\".format(newModelNameForSaving,x.split(\".\")[0]),\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=256,\n",
    "    per_device_eval_batch_size=256,\n",
    "    num_train_epochs=5,\n",
    "    seed=7,\n",
    "    load_best_model_at_end=True,\n",
    "    save_strategy='epoch',\n",
    "    overwrite_output_dir=True\n",
    "      #save_strategy = \"no\"\n",
    "  )\n",
    "\n",
    "trainer = Trainer(\n",
    "      model=model,\n",
    "      args=args,\n",
    "      train_dataset=train_dataset,\n",
    "      eval_dataset=val_dataset,\n",
    "      compute_metrics=compute_metrics,\n",
    "      callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ablstation2/.pyenv/versions/3.6.5/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 39514\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 256\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 512\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 390\n",
      "  0%|          | 0/390 [00:00<?, ?it/s]/home/ablstation2/.pyenv/versions/3.6.5/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      " 20%|██        | 78/390 [00:56<03:03,  1.70it/s]***** Running Evaluation *****\n",
      "  Num examples = 5863\n",
      "  Batch size = 256\n",
      "                                                \n",
      " 20%|██        | 78/390 [00:59<03:03,  1.70it/s]Saving model checkpoint to checkpointsMergedRobertaRemoveEmoji/roberta-base_Train_merged_Roberta_Removed_Emoji/checkpoint-78\n",
      "Configuration saved in checkpointsMergedRobertaRemoveEmoji/roberta-base_Train_merged_Roberta_Removed_Emoji/checkpoint-78/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7919630408287048, 'eval_accuracy': 0.6518847006651884, 'eval_precision': 0.6601628453594729, 'eval_recall': 0.6518847006651884, 'eval_f1': 0.6496577249745378, 'eval_runtime': 3.2581, 'eval_samples_per_second': 1799.489, 'eval_steps_per_second': 3.683, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in checkpointsMergedRobertaRemoveEmoji/roberta-base_Train_merged_Roberta_Removed_Emoji/checkpoint-78/pytorch_model.bin\n",
      "/home/ablstation2/.pyenv/versions/3.6.5/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      " 40%|████      | 156/390 [01:58<02:16,  1.71it/s]***** Running Evaluation *****\n",
      "  Num examples = 5863\n",
      "  Batch size = 256\n",
      "                                                 \n",
      " 40%|████      | 156/390 [02:02<02:16,  1.71it/s]Saving model checkpoint to checkpointsMergedRobertaRemoveEmoji/roberta-base_Train_merged_Roberta_Removed_Emoji/checkpoint-156\n",
      "Configuration saved in checkpointsMergedRobertaRemoveEmoji/roberta-base_Train_merged_Roberta_Removed_Emoji/checkpoint-156/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8035369515419006, 'eval_accuracy': 0.6433566433566433, 'eval_precision': 0.6709040312949847, 'eval_recall': 0.6433566433566433, 'eval_f1': 0.6350763319922383, 'eval_runtime': 3.3258, 'eval_samples_per_second': 1762.901, 'eval_steps_per_second': 3.608, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in checkpointsMergedRobertaRemoveEmoji/roberta-base_Train_merged_Roberta_Removed_Emoji/checkpoint-156/pytorch_model.bin\n",
      "/home/ablstation2/.pyenv/versions/3.6.5/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      " 60%|██████    | 234/390 [03:01<01:30,  1.72it/s]***** Running Evaluation *****\n",
      "  Num examples = 5863\n",
      "  Batch size = 256\n",
      "                                                 \n",
      " 60%|██████    | 234/390 [03:04<01:30,  1.72it/s]Saving model checkpoint to checkpointsMergedRobertaRemoveEmoji/roberta-base_Train_merged_Roberta_Removed_Emoji/checkpoint-234\n",
      "Configuration saved in checkpointsMergedRobertaRemoveEmoji/roberta-base_Train_merged_Roberta_Removed_Emoji/checkpoint-234/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8049021363258362, 'eval_accuracy': 0.6612655637045881, 'eval_precision': 0.6607736608427872, 'eval_recall': 0.6612655637045881, 'eval_f1': 0.6601106648234129, 'eval_runtime': 3.3374, 'eval_samples_per_second': 1756.773, 'eval_steps_per_second': 3.596, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in checkpointsMergedRobertaRemoveEmoji/roberta-base_Train_merged_Roberta_Removed_Emoji/checkpoint-234/pytorch_model.bin\n",
      "/home/ablstation2/.pyenv/versions/3.6.5/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      " 80%|████████  | 312/390 [04:04<00:45,  1.71it/s]***** Running Evaluation *****\n",
      "  Num examples = 5863\n",
      "  Batch size = 256\n",
      "                                                 \n",
      " 80%|████████  | 312/390 [04:07<00:45,  1.71it/s]Saving model checkpoint to checkpointsMergedRobertaRemoveEmoji/roberta-base_Train_merged_Roberta_Removed_Emoji/checkpoint-312\n",
      "Configuration saved in checkpointsMergedRobertaRemoveEmoji/roberta-base_Train_merged_Roberta_Removed_Emoji/checkpoint-312/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8108118176460266, 'eval_accuracy': 0.6595599522428791, 'eval_precision': 0.660352656595419, 'eval_recall': 0.6595599522428791, 'eval_f1': 0.6589347612884077, 'eval_runtime': 3.2896, 'eval_samples_per_second': 1782.308, 'eval_steps_per_second': 3.648, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in checkpointsMergedRobertaRemoveEmoji/roberta-base_Train_merged_Roberta_Removed_Emoji/checkpoint-312/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from checkpointsMergedRobertaRemoveEmoji/roberta-base_Train_merged_Roberta_Removed_Emoji/checkpoint-78 (score: 0.7919630408287048).\n",
      " 80%|████████  | 312/390 [04:09<01:02,  1.25it/s]\n",
      "Saving model checkpoint to modelMergedRemoveEmojiRoberta/roberta-base_Train_merged_Roberta_Removed_Emoji\n",
      "Configuration saved in modelMergedRemoveEmojiRoberta/roberta-base_Train_merged_Roberta_Removed_Emoji/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 249.4701, 'train_samples_per_second': 791.959, 'train_steps_per_second': 1.563, 'train_loss': 0.7256035437950721, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in modelMergedRemoveEmojiRoberta/roberta-base_Train_merged_Roberta_Removed_Emoji/pytorch_model.bin\n",
      "***** Running Prediction *****\n",
      "  Num examples = 13172\n",
      "  Batch size = 256\n",
      "/home/ablstation2/.pyenv/versions/3.6.5/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta-base\n",
      "accuracy: 0.6487245672638932\n",
      "recall: 0.6487245672638932\n",
      "precision: 0.658913727683532\n",
      "f1: 0.646815938229347\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.save_model(\"modelMergedRemoveEmojiRoberta/{}_{}\".format(newModelNameForSaving,x.split(\".\")[0]))\n",
    "\n",
    "# test_data = pd.read_csv(\"/content/ts_translated_test.tsv\",sep='\\t')\n",
    "# test_data['categorical_labels'] = test_data['label'].map(add_labels)\n",
    "\n",
    "X_test_tokenized = tokenizer(x_test_final, padding=True, truncation=True, max_length=max_length,add_special_tokens=True)\n",
    "\n",
    "\n",
    "test_dataset = Dataset(X_test_tokenized, y_test_final)\n",
    "\n",
    "\n",
    "predictions = trainer.predict(test_dataset)\n",
    "\n",
    "pred = np.argmax(predictions.predictions, axis=-1)\n",
    "\n",
    "  \n",
    "accuracy = accuracy_score(y_true=y_test_final, y_pred=pred)\n",
    "recall = recall_score(y_true=y_test_final, y_pred=pred,average='weighted')\n",
    "precision = precision_score(y_true=y_test_final, y_pred=pred,average='weighted')\n",
    "f1 = f1_score(y_true=y_test_final, y_pred=pred,average='weighted')\n",
    "\n",
    "print(model_name)\n",
    "print(\"accuracy: {}\".format(accuracy))\n",
    "print(\"recall: {}\".format(recall))\n",
    "print(\"precision: {}\".format(precision))\n",
    "print(\"f1: {}\".format(f1))\n",
    "\n",
    "\n",
    "model_results_dict['Model_Name'].append(x)\n",
    "model_results_dict['Accuracy'].append(accuracy)\n",
    "model_results_dict['Recall'].append(recall)\n",
    "model_results_dict['Precision'].append(precision)\n",
    "model_results_dict['f1'].append(f1)\n",
    "\n",
    "df = pd.DataFrame(data = model_results_dict)\n",
    "df.to_csv(\"{}_RemovedEmojiMergedDataRobertaresults.csv\".format(newModelNameForSaving))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ablstation2/.pyenv/versions/3.6.5/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.5 64-bit ('3.6.5')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9c5472c625688a4fda46769efa78306e9889cc6db92cebd22ca1efa0057f033e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
